
@inproceedings{morales_counterfactual_2023,
	title = {Counterfactual {Explanations} of {Neural} {Network}-{Generated} {Response} {Curves}},
	doi = {10.1109/IJCNN54540.2023.10191746},
	abstract = {Response curves exhibit the magnitude of the response of a sensitive system to a varying stimulus. However, response of such systems may be sensitive to multiple stimuli (i.e., input features) that are not necessarily independent. As a consequence, the shape of response curves generated for a selected input feature (referred to as “active feature”) might depend on the values of the other input features (referred to as “passive features”). In this work we consider the case of systems whose response is approximated using regression neural networks. We propose to use counterfactual explanations (CFEs) for the identification of the features with the highest relevance on the shape of response curves generated by neural network black boxes. CFEs are generated by a genetic algorithm-based approach that solves a multi-objective optimization problem. In particular, given a response curve generated for an active feature, a CFE finds the minimum combination of passive features that need to be modified to alter the shape of the response curve. We tested our method on a synthetic dataset with 1-D inputs and two crop yield prediction datasets with 2-D inputs. The relevance ranking of features and feature combinations obtained on the synthetic dataset coincided with the analysis of the equation that was used to generate the problem. Results obtained on the yield prediction datasets revealed that the impact on fertilizer responsivity of passive features depends on the terrain characteristics of each field.},
	booktitle = {2023 {International} {Joint} {Conference} on {Neural} {Networks} ({IJCNN})},
	author = {Morales, Giorgio and Sheppard, John},
	month = jun,
	year = {2023},
	note = {ISSN: 2161-4407},
	keywords = {Counterfactual explanations, Crops, deep regression, explainable machine learning, Machine learning, Mathematical models, Neural networks, Production, response curves, Shape, Training data},
	pages = {01--08},
}

@inproceedings{morales_counterfactual_2024,
	address = {Yokohama, Japan},
	title = {Counterfactual {Analysis} of {Neural} {Networks} {Used} to {Create} {Fertilizer} {Management} {Zones}},
	url = {http://arxiv.org/abs/2403.10730},
	doi = {10.48550/arXiv.2403.10730},
	abstract = {In Precision Agriculture, the utilization of management zones (MZs) that take into account within-field variability facilitates effective fertilizer management. This approach enables the optimization of nitrogen (N) rates to maximize crop yield production and enhance agronomic use efficiency. However, existing works often neglect the consideration of responsivity to fertilizer as a factor influencing MZ determination. In response to this gap, we present a MZ clustering method based on fertilizer responsivity. We build upon the statement that the responsivity of a given site to the fertilizer rate is described by the shape of its corresponding N fertilizer-yield response (N-response) curve. Thus, we generate N-response curves for all sites within the field using a convolutional neural network (CNN). The shape of the approximated N-response curves is then characterized using functional principal component analysis. Subsequently, a counterfactual explanation (CFE) method is applied to discern the impact of various variables on MZ membership. The genetic algorithm-based CFE solves a multi-objective optimization problem and aims to identify the minimum combination of features needed to alter a site's cluster assignment. Results from two yield prediction datasets indicate that the features with the greatest influence on MZ membership are associated with terrain characteristics that either facilitate or impede fertilizer runoff, such as terrain slope or topographic aspect.},
	urldate = {2024-03-25},
	booktitle = {2024 {International} {Joint} {Conference} on {Neural} {Networks} ({IJCNN}) ({IJCNN} 2024)},
	publisher = {IEEE},
	author = {Morales, Giorgio and Sheppard, John},
	month = mar,
	year = {2024},
	note = {arXiv:2403.10730 [cs]},
	keywords = {Computer Science - Machine Learning},
}

@article{morales_improved_2023,
	title = {Improved {Yield} {Prediction} of {Winter} {Wheat} {Using} a {Novel} {Two}-{Dimensional} {Deep} {Regression} {Neural} {Network} {Trained} via {Remote} {Sensing}},
	volume = {23},
	doi = {10.3390/s23010489},
	abstract = {In recent years, the use of remotely sensed and on-ground observations of crop fields, in conjunction with machine learning techniques, has led to highly accurate crop yield estimations. In this work, we propose to further improve the yield prediction task by using Convolutional Neural Networks (CNNs) given their unique ability to exploit the spatial information of small regions of the field. We present a novel CNN architecture called Hyper3DNetReg that takes in a multi-channel input raster and, unlike previous approaches, outputs a two-dimensional raster, where each output pixel represents the predicted yield value of the corresponding input pixel. Our proposed method then generates a yield prediction map by aggregating the overlapping yield prediction patches obtained throughout the field. Our data consist of a set of eight rasterized remotely-sensed features: nitrogen rate applied, precipitation, slope, elevation, topographic position index (TPI), aspect, and two radar backscatter coefficients acquired from the Sentinel-1 satellites. We use data collected during the early stage of the winter wheat growing season (March) to predict yield values during the harvest season (August). We present leave-one-out cross-validation experiments for rain-fed winter wheat over four fields and show that our proposed methodology produces better predictions than five compared methods, including Bayesian multiple linear regression, standard multiple linear regression, random forest, an ensemble of feedforward networks using AdaBoost, a stacked autoencoder, and two other CNN architectures.},
	journal = {Sensors},
	author = {Morales, Giorgio and Sheppard, John and Hegedus, Paul and Maxwell, Bruce},
	month = jan,
	year = {2023},
	pages = {489},
}

@inproceedings{morales_hyperspectral_2021,
	title = {Hyperspectral {Band} {Selection} for {Multispectral} {Image} {Classification} with {Convolutional} {Networks}},
	url = {https://ieeexplore.ieee.org/document/9533700},
	doi = {10.1109/IJCNN52387.2021.9533700},
	abstract = {In recent years, Hyperspectral Imaging (HSI) has become a powerful source for reliable data in applications such as remote sensing, agriculture, and biomedicine. However, hyperspectral images are highly data-dense and often benefit from methods to reduce the number of spectral bands while retaining the most useful information for a specific application. We propose a novel band selection method to select a reduced set of wavelengths, obtained from an HSI system in the context of image classification. Our approach consists of two main steps: the first utilizes a filter-based approach to find relevant spectral bands based on a collinearity analysis between a band and its neighbors. This analysis helps to remove redundant bands and dramatically reduces the search space. The second step applies a wrapper-based approach to select bands from the reduced set based on their information entropy values, and trains a compact Convolutional Neural Network (CNN) to evaluate the performance of the current selection. We present classification results obtained from our method and compare them to other feature selection methods on two hyperspectral image datasets. Additionally, we use the original hyperspectral data cube to simulate the process of using actual filters in a multispectral imager. We show that our method produces more suitable results for a multispectral sensor design.},
	urldate = {2024-03-05},
	booktitle = {2021 {International} {Joint} {Conference} on {Neural} {Networks} ({IJCNN})},
	author = {Morales, Giorgio and Sheppard, John and Logan, Riley and Shaw, Joseph},
	month = jul,
	year = {2021},
	note = {ISSN: 2161-4407},
	keywords = {Convolutional neural networks, Feature extraction, Information entropy, Information filters, Object recognition, Redundancy, Reliability},
	pages = {1--8},
}

@inproceedings{morales_generation_2022,
	address = {Minnesota, US},
	title = {Generation of {Site}-specific {Nitrogen} {Response} {Curves} for {Winter} {Wheat} using {Deep} {Learning}},
	abstract = {Nitrogen fertilizer response (N-response) curves are tools used to support farm management decisions. The conventional approach to model an N-response curve is to fit crop yield in response to a range of N fertilizer rates as a quadratic or exponential function. The purpose of the model is to identify the profit-maximizing N rate given the costs of nitrogen and the price paid for the crop yield. We show that N-response curves are not only field-specific but also site-specific and, as such, economic optimal (profit-maximizing) rates should be calculated for each field each year promoting the use of on-field precision experiments (OFPE) utilizing precision agriculture technologies. We propose a methodology that allows deriving N-response curves automatically instead of using parametric curve-fitting approaches. Thus, we obtain a specific non-parametric N-response curve for each 10 m x 10 m cell of a grid virtually draped on the field. First, we train a convolutional neural network called Hyper3DNetReg using remotely sensed data collected during the early stage of the winter wheat growing season (March) to predict crop harvest yield values. The neural network models the behavior of the field under different environmental and terrain conditions. Then, we use the trained prediction model to obtain an N-response curve per cell by simulating what would be the yield response given a range of nitrogen rate values between 0 and 150 pounds per acre (lbs/ac). Results show that the shape of the N-response curve depends on the region of the field from which it was calculated. Related work will address the problem of generating prescription maps that merge the site-specific economic optimal rates calculated from our N-response curves while also minimizing the overall fertilizer applied and the number of jumps between consecutive cells' nitrogen rates.},
	author = {Morales, Giorgio and Sheppard, John and Peerlinck, Amy and Hegedus, Paul and Maxwell, Bruce},
	month = jun,
	year = {2022},
}

@inproceedings{morales_two-dimensional_2021,
	title = {Two-dimensional deep regression for early yield prediction of winter wheat},
	volume = {11914},
	url = {https://www.spiedigitallibrary.org/conference-proceedings-of-spie/11914/119140H/Two-dimensional-deep-regression-for-early-yield-prediction-of-winter/10.1117/12.2612209.full},
	doi = {10.1117/12.2612209},
	abstract = {Crop yield prediction is one of the tasks of Precision Agriculture that can be automated based on multi-source periodic observations of the fields. We tackle the yield prediction problem using a Convolutional Neural Network (CNN) trained on data that combines radar satellite imagery and on-ground information. We present a CNN architecture called Hyper3DNetReg that takes in a multi-channel input image and outputs a two-dimensional raster, where each pixel represents the predicted yield value of the corresponding input pixel. We utilize radar data acquired from the Sentinel-1 satellites, while the on-ground data correspond to a set of six raster features: nitrogen rate applied, precipitation, slope, elevation, topographic position index (TPI), and aspect. We use data collected during the early stage of the winter wheat growing season (March) to predict yield values during the harvest season (August). We present experiments over four fields of winter wheat and show that our proposed methodology yields better results than five compared methods, including multiple linear regression, an ensemble of feedforward networks using AdaBoost, a stacked autoencoder, and two other CNN architectures.},
	urldate = {2024-03-05},
	booktitle = {{SPIE} {Future} {Sensing} {Technologies} 2021},
	publisher = {SPIE},
	author = {Morales, Giorgio and Sheppard, John W.},
	month = nov,
	year = {2021},
	pages = {49--63},
}

@article{morales_dual_2023,
	title = {Dual {Accuracy}-{Quality}-{Driven} {Neural} {Network} for {Prediction} {Interval} {Generation}},
	doi = {10.1109/TNNLS.2023.3339470},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	author = {Morales, Giorgio and Sheppard, John W.},
	year = {2023},
	keywords = {Artificial neural networks, Bayes methods, Companion networks, Computational modeling, Data models, deep regression, Estimation, prediction intervals (PIs), Training, Uncertainty, uncertainty quantification},
	pages = {1--11},
}

@inproceedings{morales_univariate_2024,
	address = {Vilnius, Lithuania},
	title = {Univariate {Skeleton} {Prediction} in {Multivariate} {Systems} {Using} {Transformers}},
	url = {http://arxiv.org/abs/2406.17834},
	abstract = {Symbolic regression (SR) methods attempt to learn mathematical expressions that approximate the behavior of an observed system. However, when dealing with multivariate systems, they often fail to identify the functional form that explains the relationship between each variable and the system's response. To begin to address this, we propose an explainable neural SR method that generates univariate symbolic skeletons that aim to explain how each variable influences the system's response. By analyzing multiple sets of data generated artificially, where one input variable varies while others are fixed, relationships are modeled separately for each input variable. The response of such artificial data sets is estimated using a regression neural network (NN). Finally, the multiple sets of input-response pairs are processed by a pre-trained Multi-Set Transformer that solves a problem we termed Multi-Set Skeleton Prediction and outputs a univariate symbolic skeleton. Thus, such skeletons represent explanations of the function approximated by the regression NN. Experimental results demonstrate that this method learns skeleton expressions matching the underlying functions and outperforms two GP-based and two neural SR methods.},
	urldate = {2024-06-27},
	booktitle = {Machine {Learning} and {Knowledge} {Discovery} in {Databases}},
	publisher = {arXiv},
	author = {Morales, Giorgio and Sheppard, John W.},
	month = jun,
	year = {2024},
	note = {arXiv:2406.17834 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
}

@article{morales_hyperspectral_2021-1,
	title = {Hyperspectral {Dimensionality} {Reduction} {Based} on {Inter}-{Band} {Redundancy} {Analysis} and {Greedy} {Spectral} {Selection}},
	volume = {13},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2072-4292},
	url = {https://www.mdpi.com/2072-4292/13/18/3649},
	doi = {10.3390/rs13183649},
	abstract = {Hyperspectral imaging systems are becoming widely used due to their increasing accessibility and their ability to provide detailed spectral responses based on hundreds of spectral bands. However, the resulting hyperspectral images (HSIs) come at the cost of increased storage requirements, increased computational time to process, and highly redundant data. Thus, dimensionality reduction techniques are necessary to decrease the number of spectral bands while retaining the most useful information. Our contribution is two-fold: First, we propose a filter-based method called interband redundancy analysis (IBRA) based on a collinearity analysis between a band and its neighbors. This analysis helps to remove redundant bands and dramatically reduces the search space. Second, we apply a wrapper-based approach called greedy spectral selection (GSS) to the results of IBRA to select bands based on their information entropy values and train a compact convolutional neural network to evaluate the performance of the current selection. We also propose a feature extraction framework that consists of two main steps: first, it reduces the total number of bands using IBRA; then, it can use any feature extraction method to obtain the desired number of feature channels. We present classification results obtained from our methods and compare them to other dimensionality reduction methods on three hyperspectral image datasets. Additionally, we used the original hyperspectral data cube to simulate the process of using actual filters in a multispectral imager.},
	language = {en},
	number = {18},
	urldate = {2024-03-05},
	journal = {Remote Sensing},
	author = {Morales, Giorgio and Sheppard, John W. and Logan, Riley D. and Shaw, Joseph A.},
	month = jan,
	year = {2021},
	note = {Number: 18
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {band selection, hyperspectral classification, hyperspectral feature extraction, multispectral classification},
	pages = {3649},
}

@article{morales_reduced-cost_2020,
	title = {Reduced-cost hyperspectral convolutional neural networks},
	volume = {14},
	issn = {1931-3195, 1931-3195},
	url = {https://www.spiedigitallibrary.org/journals/journal-of-applied-remote-sensing/volume-14/issue-3/036519/Reduced-cost-hyperspectral-convolutional-neural-networks/10.1117/1.JRS.14.036519.full},
	doi = {10.1117/1.JRS.14.036519},
	abstract = {Hyperspectral imaging provides a useful tool for extracting complex information when visual spectral bands are not enough to solve certain tasks. However, processing hyperspectral images (HSIs) is usually computationally expensive due to the great amount of both spatial and spectral data they incorporate. We present a low-cost convolutional neural network designed for HSI classification. Its architecture consists of two parts: a series of densely connected three-dimensional (3-D) convolutions used as a feature extractor, and a series of two-dimensional (2-D) separable convolutions used as a spatial encoder. We show that this design involves fewer trainable parameters compared to other approaches, yet without detriment to its performance. What is more, we achieve comparable state-of-the-art results testing our architecture on four public remote sensing datasets: Indian Pines, Pavia University, Salinas, and EuroSAT; and a dataset of Kochia leaves [Bassia scoparia] with three different levels of herbicide resistance. The source code and datasets are available online. (Hyper3DNet codebase: https://github.com/GiorgioMorales/hyper3dnet.)},
	number = {3},
	urldate = {2024-03-05},
	journal = {Journal of Applied Remote Sensing},
	author = {Morales, Giorgio and Sheppard, John W. and Scherrer, Bryan and Shaw, Joseph A.},
	month = sep,
	year = {2020},
	note = {Publisher: SPIE},
	pages = {036519},
}

@article{huaman_regression_2019,
	title = {Regression {Models} between {Active} {Sensor}-{Measured} {NDVI} and {UAV}-{Acquired} {Multispectral} {Images} with {Positioning} {Uncertainty}},
	volume = {17},
	issn = {1548-0992},
	url = {https://ieeexplore.ieee.org/document/8896829},
	doi = {10.1109/TLA.2019.8896829},
	abstract = {Nowadays, it is frequent to monitor large crop areas using high-precision active sensors for measuring NDVI or multispectral cameras mounted on UAVs. However, the NDVI calculations using multispectral images differ from the readings of an active sensor for the same object or surface. What is more, there is a difference between the NDVI values of two multispectral images taken with different lighting conditions or height over the same object. In this paper, we propose new models to estimate NDVI using aerial images from a multispectral camera with values comparable to those of a portable active sensor. For this, we propose a methodology where three lambertian reflection surfaces are chosen and characterized with a hyperspectral camera. These surfaces appear in the aerial images and are used as control points of three NDVI values in the range of 0 to 1. Then, a linear model and an exponential model, derived from the original NDVI calculation expression, are proposed and evaluated, using the spectral information of the pixels inside a region equivalent to the active sensor reflection zone and the NDVI measurements of the same sensor. After the conditioning of the data, the parameters of the models are obtained by calculating the minimum squared errors. In addition, we have done a set of tests to verify the variations of the parameters versus the positioning uncertainty, different lighting conditions and different heights in the range of 15 to 40 m. The results show that the parameters of the two proposed models vary with the height, maintaining the absolute differences of NDVI close to 0.01, which is equivalent to the resolution of the active sensor; the smallest differences occur for the linear model in the interpolation interval, while the exponential model has a high accuracy near the upper limit of NDVI.},
	number = {06},
	urldate = {2024-06-28},
	journal = {IEEE Latin America Transactions},
	author = {Huaman, S. and Castro, A. and Morales, G. and Telles, J.},
	month = jun,
	year = {2019},
	note = {Conference Name: IEEE Latin America Transactions},
	keywords = {Biomedical imaging, Cameras, Color, image resolution, Image resolution, Instruments, minimum square error, Monitoring, multispectral imagery, Regression, uncertainty, Uncertainty},
	pages = {1055--1067},
	file = {IEEE Xplore Full Text PDF:C\:\\Users\\w63x712\\Zotero\\storage\\FC48LLLD\\Huaman et al. - 2019 - Regression Models between Active Sensor-Measured N.pdf:application/pdf},
}

@article{morales_automatic_2018,
	title = {Automatic {Segmentation} of {Mauritia} flexuosa in {Unmanned} {Aerial} {Vehicle} ({UAV}) {Imagery} {Using} {Deep} {Learning}},
	volume = {9},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1999-4907},
	url = {https://www.mdpi.com/1999-4907/9/12/736},
	doi = {10.3390/f9120736},
	abstract = {One of the most important ecosystems in the Amazon rainforest is the Mauritia flexuosa swamp or “aguajal”. However, deforestation of its dominant species, the Mauritia flexuosa palm, also known as “aguaje”, is a common issue, and conservation is poorly monitored because of the difficult access to these swamps. The contribution of this paper is twofold: the presentation of a dataset called MauFlex, and the proposal of a segmentation and measurement method for areas covered in Mauritia flexuosa palms using high-resolution aerial images acquired by UAVs. The method performs a semantic segmentation of Mauritia flexuosa using an end-to-end trainable Convolutional Neural Network (CNN) based on the Deeplab v3+ architecture. Images were acquired under different environment and light conditions using three different RGB cameras. The MauFlex dataset was created from these images and it consists of 25,248 image patches of     512 × 512     pixels and their respective ground truth masks. The results over the test set achieved an accuracy of 98.143\%, specificity of 96.599\%, and sensitivity of 95.556\%. It is shown that our method is able not only to detect full-grown isolated Mauritia flexuosa palms, but also young palms or palms partially covered by other types of vegetation.},
	language = {en},
	number = {12},
	urldate = {2024-06-28},
	journal = {Forests},
	author = {Morales, Giorgio and Kemper, Guillermo and Sevillano, Grace and Arteaga, Daniel and Ortega, Ivan and Telles, Joel},
	month = dec,
	year = {2018},
	note = {Number: 12
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {\textit{Mauritia flexuosa}, convolutional neural network, end-to-end learning, forest inventory, semantic segmentation},
	pages = {736},
	file = {Full Text PDF:C\:\\Users\\w63x712\\Zotero\\storage\\NBYJGB2K\\Morales et al. - 2018 - Automatic Segmentation of Mauritia flexuosa in Unm.pdf:application/pdf},
}

@inproceedings{morales_cloud_2019,
	address = {Cham},
	title = {Cloud {Detection} for {PERUSAT}-1 {Imagery} {Using} {Spectral} and {Texture} {Descriptors}, {ANN}, and {Panchromatic} {Fusion}},
	isbn = {978-3-319-93112-8},
	doi = {10.1007/978-3-319-93112-8_1},
	abstract = {The cloud detection process is a prerequisite for many remote sensing applications in order to use only those cloud-free parts of satellite images and reduce errors of further automatic detection algorithms. In this paper, we present a method to detect clouds in high-resolution images of 2.8 m per pixel approximately. The process is performed over those pixels that exceed a defined threshold of blue normalized difference vegetation index to reduce the execution time. From each pixel, a set of texture descriptors and reflectance descriptors are processed in an Artificial Neural Network. The texture descriptors are extracted using the Gray-Level Co-occurrence Matrix. Each detection result passes through a false-positive discard procedure on the blue component of the panchromatic fusion based on image processing techniques such as Region growing, Hough transform, among others. The results show a minimum Kappa coefficient of 0.80 and an average of 0.94 over a set of 25 images from the Peruvian satellite PERUSAT-1, operational since December 2016.},
	language = {en},
	booktitle = {Proceedings of the 3rd {Brazilian} {Technology} {Symposium}},
	publisher = {Springer International Publishing},
	author = {Morales, Giorgio and Huamán, Samuel G. and Telles, Joel},
	editor = {Iano, Yuzo and Arthur, Rangel and Saotome, Osamu and Vieira Estrela, Vania and Loschi, Hermes José},
	year = {2019},
	keywords = {Artificial neural networks, Cloud detection, High-resolution, Texture analysis},
	pages = {1--7},
	file = {Full Text PDF:C\:\\Users\\w63x712\\Zotero\\storage\\JG8FRZM3\\Morales et al. - 2019 - Cloud Detection for PERUSAT-1 Imagery Using Spectr.pdf:application/pdf},
}

@inproceedings{morales_cloud_2018,
	address = {Cham},
	title = {Cloud {Detection} in {High}-{Resolution} {Multispectral} {Satellite} {Imagery} {Using} {Deep} {Learning}},
	isbn = {978-3-030-01424-7},
	doi = {10.1007/978-3-030-01424-7_28},
	abstract = {Cloud detection in high-resolution satellite images is a critical step for many remote sensing applications, but also a challenge, as such images have limited spectral bands. The contribution of this paper is twofold: We present a dataset called CloudPeru as well as a methodology for cloud detection in multispectral satellite images (approximately 2.8 meters per pixel) using deep learning. We prove that an agile Convolutional Neural Network (CNN) is able to distinguish between non-clouds and different types of clouds, including thin and very small ones, and achieve a classification accuracy of 99.94\%. Each image is subdivided into superpixels by the SLICO algorithm, which are then processed by the trained CNN. Finally, we obtain the cloud mask by applying a threshold of 0.5 on the probability map. The results are compared with manually annotated images, showing a Kappa coefficient of 0.944, which is higher than that of compared methods.},
	language = {en},
	booktitle = {Artificial {Neural} {Networks} and {Machine} {Learning} – {ICANN} 2018},
	publisher = {Springer International Publishing},
	author = {Morales, Giorgio and Huamán, Samuel G. and Telles, Joel},
	editor = {Kůrková, Věra and Manolopoulos, Yannis and Hammer, Barbara and Iliadis, Lazaros and Maglogiannis, Ilias},
	year = {2018},
	keywords = {Cloud detection, Convolutional neural networks, Deep learning, High-resolution},
	pages = {280--288},
	file = {Full Text PDF:C\:\\Users\\w63x712\\Zotero\\storage\\6FCU4ICB\\Morales et al. - 2018 - Cloud Detection in High-Resolution Multispectral S.pdf:application/pdf},
}

@inproceedings{palomino_petefa_2018,
	title = {{PETEFA}: {Geographic} {Information} {System} for {Precision} {Agriculture}},
	shorttitle = {{PETEFA}},
	url = {https://ieeexplore.ieee.org/abstract/document/8526414},
	doi = {10.1109/INTERCON.2018.8526414},
	abstract = {Providing timely information through remote sensing tools to the farmers and to the National Institute of Agrarian Innovation (INIA) is important to manage the production of yellow corn crops (Zea Mays) in the region of Lambayeque, Peru. This paper addresses three objectives by providing information in different levels: First, provide information about the Normalized Difference Vegetation Index (NDVI) from crops in their different stages during their lifecycle; secondly, provide georeferenced soil analysis information organized by parcels and, finally, provide information about evapotranspiration of each parcel calculated using weather station sensors, soil type, land uses and georefer-enced NDVI masks. All this information is provided through a Geographic Information System called Remote Sensing Platform for Agricultural Purposes (PETEFA), which is based on open source tools. In short, PETEFA is a monitoring tool that provides information through a computer or mobile device to the farmers or the INIA.},
	urldate = {2024-06-28},
	booktitle = {2018 {IEEE} {XXV} {International} {Conference} on {Electronics}, {Electrical} {Engineering} and {Computing} ({INTERCON})},
	author = {Palomino, Walther and Morales, Giorgio and Huamán, Samuel and Telles, Joel},
	month = aug,
	year = {2018},
	keywords = {Agriculture, Geographic information systems, PostGIS, Remote sensing, satellite image, Satellites, Software, Soil, Tools, UAV, yellow corn},
	pages = {1--4},
	file = {IEEE Xplore Full Text PDF:C\:\\Users\\w63x712\\Zotero\\storage\\VTV62LWP\\Palomino et al. - 2018 - PETEFA Geographic Information System for Precisio.pdf:application/pdf},
}

@inproceedings{morales_shadow_2018,
	title = {Shadow {Detection} in {High}-{Resolution} {Multispectral} {Satellite} {Imagery} {Using} {Generative} {Adversarial} {Networks}},
	url = {https://ieeexplore.ieee.org/document/8526416},
	doi = {10.1109/INTERCON.2018.8526416},
	abstract = {Detecting shadows in high-resolution satellite images is a challenging task due to the fact that shadows can easily be mistaken for low reflectance soil or water and that such images have limited spectral bands. In this work, we propose a semantic level shadow segmentation by using generative adversarial networks and created a dataset of pre-processed images for training, validation and test. In this way, we trained a generator network that produces shadow masks with condition on a satellite image patch and tries to fool a discriminator, which is trained to discern if a given mask comes from the ground truth or from the generator model. The results achieve an accuracy of 95.85\% and a Kappa coefficient of 91.76\%, which is superior to the compared methods.},
	urldate = {2024-06-28},
	booktitle = {2018 {IEEE} {XXV} {International} {Conference} on {Electronics}, {Electrical} {Engineering} and {Computing} ({INTERCON})},
	author = {Morales, Giorgio and Arteaga, Daniel and Huamán, Samuel G. and Telles, Joel and Palomino, Walther},
	month = aug,
	year = {2018},
	keywords = {Decoding, end-to-end learning, Generative adversarial networks, Generative Adversarial Networks, Generators, Measurement, satellite image, Satellites, Shadow detection, Support vector machines, Training},
	pages = {1--4},
	file = {IEEE Xplore Full Text PDF:C\:\\Users\\w63x712\\Zotero\\storage\\56QXWUG5\\Morales et al. - 2018 - Shadow Detection in High-Resolution Multispectral .pdf:application/pdf},
}

@inproceedings{morales_detecting_2019,
	address = {Cham},
	title = {Detecting {Violent} {Robberies} in {CCTV} {Videos} {Using} {Deep} {Learning}},
	isbn = {978-3-030-19823-7},
	doi = {10.1007/978-3-030-19823-7_23},
	abstract = {Video surveillance through security cameras has become difficult due to the fact that many systems require manual human inspection for identifying violent or suspicious scenarios, which is practically inefficient. Therefore, the contribution of this paper is twofold: the presentation of a video dataset called UNI-Crime, and the proposal of a violent robbery detection method in CCTV videos using a deep-learning sequence model. Each of the 30 frames of our videos passes through a pre-trained VGG-16 feature extractor; then, all the sequence of features is processed by two convolutional long-short term memory (convLSTM) layers; finally, the last hidden state passes through a series of fully-connected layers in order to obtain a single classification result. The method is able to detect a variety of violent robberies (i.e., armed robberies involving firearms or knives, or robberies showing different level of aggressiveness) with an accuracy of 96.69\%.},
	language = {en},
	booktitle = {Artificial {Intelligence} {Applications} and {Innovations}},
	publisher = {Springer International Publishing},
	author = {Morales, Giorgio and Salazar-Reque, Itamar and Telles, Joel and Díaz, Daniel},
	editor = {MacIntyre, John and Maglogiannis, Ilias and Iliadis, Lazaros and Pimenidis, Elias},
	year = {2019},
	keywords = {Action recognition, convLSTM, Robbery detection},
	pages = {282--291},
	file = {Full Text PDF:C\:\\Users\\w63x712\\Zotero\\storage\\Z896VJRS\\Morales et al. - 2019 - Detecting Violent Robberies in CCTV Videos Using D.pdf:application/pdf},
}

@inproceedings{morales_shadow_2019,
	address = {Cham},
	title = {Shadow {Removal} in {High}-{Resolution} {Satellite} {Images} {Using} {Conditional} {Generative} {Adversarial} {Networks}},
	isbn = {978-3-030-11680-4},
	doi = {10.1007/978-3-030-11680-4_31},
	abstract = {In satellite image processing, obscure zones that were affected by shadows are normally discarded from further processing. Nevertheless, for specific applications, such as surveillance, it is desirable to remove shadows despite the fact that reconstructed zones do not necessarily have real reflectance values. In that sense, we propose a shadow removal method in high-resolution satellite images using conditional Generative Adversarial Networks (cGANs). The generator network is trained to produce shadow-free RGB images with condition on a satellite image patch altered with artificial shadows and concatenated with its respective binary shadow mask, while the discriminator is adversely trained to discern if a given shadow-free image comes from the generator or if it is an original RGB image without artificial alteration. The method is tested in the proposed dataset achieving an error ratio comparable with the state of the art. Finally, we confirm the feasibility of the proposed network using real shadowed images.},
	language = {en},
	booktitle = {Information {Management} and {Big} {Data}},
	publisher = {Springer International Publishing},
	author = {Morales, Giorgio and Huamán, Samuel G. and Telles, Joel},
	editor = {Lossio-Ventura, Juan Antonio and Muñante, Denisse and Alatrista-Salas, Hugo},
	year = {2019},
	keywords = {Generative Adversarial Networks, Satellite imagery, Shadow removal},
	pages = {328--340},
	file = {Full Text PDF:C\:\\Users\\w63x712\\Zotero\\storage\\S6XQVI73\\Morales et al. - 2019 - Shadow Removal in High-Resolution Satellite Images.pdf:application/pdf},
}

@inproceedings{morales_end--end_2019,
	title = {End-to-end {Cloud} {Segmentation} in {High}-{Resolution} {Multispectral} {Satellite} {Imagery} {Using} {Deep} {Learning}},
	url = {https://ieeexplore.ieee.org/document/8853549},
	doi = {10.1109/INTERCON.2019.8853549},
	abstract = {Segmenting clouds in high-resolution satellite images is an arduous and challenging task due to the many types of geographies and clouds a satellite can capture. Therefore, it needs to be automated and optimized, specially for those who regularly process great amounts of satellite images, such as governmental institutions. In that sense, the contribution of this work is twofold: We present the CloudPeru2 dataset, consisting of 22,400 images of 512 × 512 pixels and their respective hand-drawn cloud masks, as well as the proposal of an end-to-end segmentation method for clouds using a Convolutional Neural Network (CNN) based on the Deeplab v3+ architecture. The results over the test set achieved an accuracy of 96.62\%, precision of 96.46\%, specificity of 98.53\%, and sensitivity of 96.72\% which is superior to the compared methods.},
	urldate = {2024-06-28},
	booktitle = {2019 {IEEE} {XXVI} {International} {Conference} on {Electronics}, {Electrical} {Engineering} and {Computing} ({INTERCON})},
	author = {Morales, Giorgio and Ramírez, Alejandro and Telles, Joel},
	month = aug,
	year = {2019},
	keywords = {Cloud segmentation, Convolution, end-to-end learning, Feature extraction, Image segmentation, Measurement, Remote sensing, satellite image, Satellites, Training},
	pages = {1--4},
	file = {IEEE Xplore Full Text PDF:C\:\\Users\\w63x712\\Zotero\\storage\\83IRCF6N\\Morales et al. - 2019 - End-to-end Cloud Segmentation in High-Resolution M.pdf:application/pdf},
}

@inproceedings{apolinario_estimation_2019,
	title = {Estimation of {2D} {Velocity} {Model} using {Acoustic} {Signals} and {Convolutional} {Neural} {Networks}},
	url = {https://ieeexplore.ieee.org/document/8853566},
	doi = {10.1109/INTERCON.2019.8853566},
	abstract = {The parameters estimation of a system using indirect measurements over the same system is a problem that occurs in many fields of engineering, known as the inverse problem. It also happens in the field of underwater acoustic, especially in mediums that are not transparent enough. In those cases, shape identification of objects using only acoustic signals is a challenge because it is carried out with information of echoes that are produced by objects with different densities from that of the medium. In general, these echoes are difficult to understand since their information is usually noisy and redundant. In this paper, we propose a model of convolutional neural network with an Encoder-Decoder configuration to estimate both localization and shape of objects, which produce reflected signals. This model allows us to obtain a 2D velocity model. The model was trained with data generated by the finite-difference method, and it achieved a value of 98.58\% in the intersection over union metric 75.88\% in precision and 64.69\% in sensitivity.},
	urldate = {2024-06-28},
	booktitle = {2019 {IEEE} {XXVI} {International} {Conference} on {Electronics}, {Electrical} {Engineering} and {Computing} ({INTERCON})},
	author = {Apolinario, Marco Paul E. and Huaman Bustamante, Samuel G. and Morales, Giorgio and Diaz, Daniel},
	month = aug,
	year = {2019},
	keywords = {Acoustic Wave Equation, Convolution, Decoding, Deep Learning, Encoder-Decoder, Finite-Difference Method, Inverse problems, Mathematical model, Shape, Training, Two dimensional displays},
	pages = {1--4},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\w63x712\\Zotero\\storage\\65DJHAHY\\8853566.html:text/html;IEEE Xplore Full Text PDF:C\:\\Users\\w63x712\\Zotero\\storage\\DDQQ5LLJ\\Apolinario et al. - 2019 - Estimation of 2D Velocity Model using Acoustic Sig.pdf:application/pdf},
}

@inproceedings{peerlinck_optimizing_2022,
	address = {Minnesota, US},
	title = {Optimizing {Nitrogen} {Application} to {Maximize} {Yield} and {Reduce} {Environmental} {Impact} in {Winter} {Wheat} {Production}},
	abstract = {Field-specific fertilizer rate optimization is known to be beneficial for improving farming profit, and profits can be further improved by dividing the field into smaller plots and applying site-specific rates across the field. Finding optimal rates for these plots is often based on data gathered from the plots, which are used to determine a yield response curve, telling us how much fertilizer needs to be applied to maximize yield. In this research, we trained a Random Forest to create plot-specific non-parametric yield response curves. We then use these curves to determine the optimal amount of fertilizer to be applied to specific plots by maximizing a net return function based on these curves. However, we claim that there are additional issues that should be taken into account when designing optimal prescription maps. In addition to optimizing yield, we want to reduce strain on farming equipment by minimizing rate jumps between consecutive cells. This helps machines run more efficiently and last longer, thus reducing waste. Furthermore, when creating these optimized prescription maps, we also aim to improve environmental impact by reducing the overall fertilizer applied, as excess nitrogen seeps into the soil and drains into our waterways, negatively affecting water quality. In previous work, we found that it is possible to reduce overall fertilizer applied by 5 to 10\% when creating experimental prescription maps without significantly impacting yield. Therefore, we hypothesize this will hold true for optimized prescription maps as well. We address these three separate, competing objectives using an adjusted genetic algorithm, known as Non-Dominated Sorting Genetic Algorithm II (NSGA-II), which finds a set of potential solutions that are optimal for the combined objectives. Such solutions are known as Pareto optimal, where one of the objectives cannot be improved without negatively impacting at least one other objective. We further adjust NSGA-II to use the Factored Evolutionary Algorithm (FEA) framework, which decomposes the variables into separate, overlapping groups to increase exploration of the search space, as well as enabling the ability to parallelize computation.},
	author = {Peerlinck, Amy and Morales, Giorgio and Sheppard, John and Hegedus, Paul and Maxwell, Bruce},
	month = jun,
	year = {2022},
}

@inproceedings{maxwell_decision_2022,
	address = {Minnesota, US},
	title = {Decision {Support} {From} {On}-{Field} {Precision} {Experiments}},
	abstract = {Empirically driven adaptive management in large-scale commodity crop production has become possible with spatially controlled application and sub-field scale crop monitoring technology. Site-specific experimentation is fundamental to an agroecosystem adaptive management (AAM) framework that results in information for growers to make informed decisions about their practices with their local data. Crop production and quality response data from combine harvester mounted sensors and internet-available remote sensing allows spatial variability assessment of the experimentally applied input as well as the impact of environment and management covariates that also spatially vary across the field. Repeating the experiments and gathering year-specific economic and weather data allows for incorporating temporal variability into simulation models driven by the locally parameterized crop response models. Field-specific simulation allows comparison of input management alternatives to identify practices that provide the greatest profitability, minimization of pollution from the inputs, and economic resilience. Communication of information to farmers through carefully designed decision support will determine if precision agriculture (PA) provides transparent interactive algorithms that empower farmers to become more knowledgeable agroecologists, or becomes the end point of industrialized agriculture that removes human decisions from agriculture.},
	author = {Maxwell, Bruce and Hegedus, Paul and Loewen, Sasha and Duff, Hannah and Sheppard, John and Peerlinck, Amy and Morales, Giorgio and Bekkerman, Anton},
	month = jun,
	year = {2022},
}

@mastersthesis{morales_towards_2021,
	title = {Towards reduced-cost hyperspectral and multispectral image classification},
	copyright = {Copyright 2021 by Giorgio L. Morales Luna},
	url = {https://scholarworks.montana.edu/xmlui/handle/1/16643},
	abstract = {In recent years, Hyperspectral Imaging systems (HSI) have become a powerful source for reliable data in applications such as remote sensing, agriculture, and biomedicine. However, the abundant spectral and spatial information of hyperspectral images makes them highly complex, which leads to the need for specialized Machine Learning algorithms to process and classify them. In that sense, the contribution of this thesis is multi-folded. We present a low-cost convolutional neural network designed for hyperspectral image classification called Hyper3DNet. Its architecture consists of two parts: a series of densely connected 3-D convolutions used as a feature extractor, and a series of 2-D separable convolutions used as a spatial encoder. We show that this design involves fewer trainable parameters compared to other approaches, yet without detriment to its performance. Furthermore, having observed that hyperspectral images benefit from methods to reduce the number of spectral bands while retaining the most useful information for a specific application, we present two novel hyperspectral dimensionality reduction techniques. First, we propose a filter-based method called Inter-Band Redundancy Analysis (IBRA) based on a collinearity analysis between a band and its neighbors. This analysis helps to remove redundant bands and dramatically reduces the search space. Second, we apply a wrapper-based approach called Greedy Spectral Selection (GSS) to the results of IBRA to select bands based on their information entropy values and train a compact Convolutional Neural Network to evaluate the performance of the current selection. We also propose a feature extraction framework that consists of two main steps: first, it reduces the total number of bands using IBRA; then, it can use any feature extraction method to obtain the desired number of feature channels. Finally, we use the original hyperspectral data cube to simulate the process of using actual filters in a multispectral imager. Experimental results show that our proposed Hyper3DNet architecture in conjunction with our dimensionality reduction techniques yields better classification results than the compared methods, producing more suitable results for a multispectral sensor design.},
	language = {en},
	urldate = {2024-03-05},
	school = {Montana State University},
	author = {Morales, Giorgio},
	year = {2021},
	note = {Accepted: 2022-06-10T18:58:51Z},
}
